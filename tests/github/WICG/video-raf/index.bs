<pre class='metadata'>
Title: HTMLVideoElement.requestAnimationFrame()
Repository: wicg/video-raf
Status: CG-DRAFT
ED: https://wicg.github.io/video-raf/
Shortname: video-raf
Level: 1
Group: wicg
Editor: Thomas Guilbert, w3cid 120583, Google Inc. https://google.com/
Abstract: &lt;video&gt;.requestAnimationFrame() allows web authors to be notified after a frame has been presented for composition.
!Participate: <a href="https://github.com/wicg/video-raf">Git Repository.</a>
!Participate: <a href="https://github.com/wicg/video-raf/issues/new">File an issue.</a>
!Version History: <a href="https://github.com/wicg/video-raf/commits">https://github.com/wicg/video-raf/commits</a>
Indent: 2
Markup Shorthands: markdown yes
</pre>

<pre class='anchors'>
  spec: hr-timing; urlPrefix: https://w3c.github.io/hr-time/
    type: dfn
      for: Clock resolution; text: clock resolution; url: #clock-resolution
  spec: html; urlPrefix: https://html.spec.whatwg.org/multipage/imagebitmap-and-animations.html
    type: dfn
      text: run the animation frame callbacks; url: #run-the-animation-frame-callbacks
    type:attribute; for:CanvasRenderingContext2D; text:canvas
  spec: css-values; urlPrefix: https://drafts.csswg.org/css-values/
    type: dfn
      text: CSS pixels; url: #px
  spec: media-capabilities; urlPrefix: https://w3c.github.io/media-capabilities
    type: dictionary
      text: MediaCapabilitiesInfo; url: #dictdef-mediacapabilitiesinfo
  spec: media-playback-quality; urlPrefix: https://w3c.github.io/media-playback-quality/
    type: attribute
      for: VideoPlaybackQuality; text: droppedVideoFrames; url: #dom-videoplaybackquality-droppedvideoframes
</pre>


# Introduction #    {#introduction}

*This section is non-normative*

This is a proposal to add a {{AnimationFrameProvider|requestAnimationFrame()}} method to the {{HTMLVideoElement}}.

This method allows web authors to register a {{VideoFrameRequestCallback|callback}} which runs in the
[=update the rendering|rendering steps=], when a new video frame is sent to the compositor. The
new {{VideoFrameRequestCallback|callbacks}} are executed immediately before existing
{{AnimationFrameProvider|window.requestAnimationFrame()}} callbacks. Changes made from within both
callback types within the same [=event loop processing model|turn of the event loop=] will be visible on
screen at the same time, with the next v-sync.

Drawing operations (e.g. drawing a video frame to a {{canvas}} via {{drawImage()}}) made through this
API will be synchronized as a *best effort* with the video playing on screen. *Best effort* in this case
means that, even with a normal work load, a {{VideoFrameRequestCallback|callback}} can occasionally be
fired one v-sync late, relative to when the new video frame was presented. This means that drawing
operations might occasionally appear on screen one v-sync after the video frame does. Additionally, if
there is a heavy load on the main thread, we might not get a callback for every frame (as measured by a
discontinuity in the {{presentedFrames}}).

Note: A web author could know if a callback is late by checking whether {{expectedDisplayTime}} is equal
to *now*, as opposed to roughly one v-sync in the future.

The {{VideoFrameRequestCallback}} also provides useful {{VideoFrameMetadata|metadata}} about the video
frame that was most recently presented for composition, which can be used for automated metrics analysis.

# VideoFrameMetadata #    {#video-frame-metadata}

<pre class='idl'>
  dictionary VideoFrameMetadata {
    required DOMHighResTimeStamp timePresented;
    required DOMHighResTimeStamp expectedDisplayTime;

    required unsigned long width;
    required unsigned long height;

    double presentationTimestamp;
    double elapsedProcessingTime;
    unsigned long presentedFrames;
    DOMHighResTimeStamp captureTime;
    DOMHighResTimeStamp receiveTime;
    unsigned long rtpTimestamp;
  };
</pre>

## Definitions ## {#video-frame-metadata-definitions}

<dfn>media pixels</dfn> are defined as a media resource's visible decoded pixels, without pixel aspect
ratio adjustments. They are different from [=CSS pixels=], which account for pixel aspect ratio
adjustments.

## Attributes ## {#video-frame-metadata-attributes}

: <dfn for="VideoFrameMetadata" dict-member>timePresented</dfn>
:: The time at which the user agent submitted the frame for composition.

: <dfn for="VideoFrameMetadata" dict-member>expectedDisplayTime</dfn>
:: The time at which the user agent expects the frame to be visible.

: <dfn for="VideoFrameMetadata" dict-member>width</dfn>
:: The width of the video frame, in [=media pixels=].

: <dfn for="VideoFrameMetadata" dict-member>height</dfn>
:: The height of the video frame, in [=media pixels=].

Note: {{width}} and {{height}} might differ from {{HTMLVideoElement/videoWidth|videoWidth}} and
{{HTMLVideoElement/videoHeight|videoHeight}} in certain cases (e.g, an anamorphic video might
have rectangular pixels). When a calling
<a href="https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/texImage2D">`texImage2D()`</a>,
{{width}} and {{height}} are the dimensions used to copy the video's [=media pixels=] to the texture.

: <dfn for="VideoFrameMetadata" dict-member>presentationTimestamp</dfn>
::  The media presentation timestamp in seconds of the frame presented (e.g. its
  timestamp on the {{HTMLMediaElement/currentTime|video.currentTime}} timeline).
  May not be known to the compositor or exist in all cases.

: <dfn for="VideoFrameMetadata" dict-member>elapsedProcessingTime</dfn>
::  The elapsed time in seconds from submission of the encoded packet with
  the same presentationTimestamp as this frame to the decoder until the
  decoded frame was ready for presentation.

:: In addition to decoding time, may include processing time. E.g., YUV
  conversion and/or staging into GPU backed memory.

: <dfn for="VideoFrameMetadata" dict-member>presentedFrames</dfn>
::  A count of the number of frames submitted for composition. Allows clients
  to determine if frames were missed between {{VideoFrameRequestCallback}}s.

: <dfn for="VideoFrameMetadata" dict-member>captureTime</dfn>
::  For video frames coming from either a local or remote source, this is the
  time at which the frame was captured by the camera. For a remote source, the
  capture time is estimated using clock synchronization and RTCP sender reports
  to convert RTP timestamps to capture time as specified in
  [[RFC3550#section-6.4.1|RFC 3550 Section 6.4.1]]

: <dfn for="VideoFrameMetadata" dict-member>receiveTime</dfn>
::  For video frames coming from a remote source, this is the
  time the encoded frame was received by the platform, i.e., the time at
  which the last packet belonging to this frame was received over the network.

: <dfn for="VideoFrameMetadata" dict-member>rtpTimestamp</dfn>
::  The RTP timestamp associated with this video frame.

# VideoFrameRequestCallback #    {#video-frame-request-callback}

<pre class='idl'>
  callback VideoFrameRequestCallback = void(DOMHighResTimeStamp now, VideoFrameMetadata metadata);
</pre>

Each {{VideoFrameRequestCallback}} object has a <dfn>canceled</dfn> boolean initially set to false.

# HTMLVideoElement.requestAnimationFrame() #  {#video-raf}
<pre class='idl'>
  partial interface HTMLVideoElement {
      unsigned long requestAnimationFrame(VideoFrameRequestCallback callback);
      void cancelAnimationFrame(unsigned long handle);
  };
</pre>

## Methods ## {#video-raf-methods}

Each {{HTMLVideoElement}} has a <dfn>list of animation frame callbacks</dfn>, which is initially empty,
and a <dfn>last presented frame indentifier</dfn>, which is a number which is initialy zero.
The {{HTMLVideoElement}}'s {{ownerDocument}} also has a <dfn>animation frame
callback identifier</dfn>, which is a number which is initially zero.

: <dfn for="HTMLVideoElement" method>requestAnimationFrame(|callback|)</dfn>
:: Registers a callback to be fired the next time a frame is presented to the compositor.

   When `requestAnimationFrame` is called, the user agent MUST run the following steps:
     1. Let |video| be the {{HTMLVideoElement}} on which `requestAnimationFrame` is
        invoked.
     1. Increment |video|'s {{ownerDocument}}'s [=animation frame callback identifier=] by one.
     1. Let |callbackId| be |video|'s {{ownerDocument}}'s [=animation frame callback identifier=]
     1. Append |callback| to |video|'s [=list of animation frame callbacks=], associated with |callbackId|.
     1. Return |callbackId|.

: <dfn for="HTMLVideoElement" method>cancelAnimationFrame(|handle|)</dfn>
:: Cancels an existing video frame request callback given its handle.

  When `cancelAnimationFrame` is called, the user agent MUST run the following steps:

  1. Let |video| be the target {{HTMLVideoElement}} object on which `cancelAnimationFrame` is invoked.
  1. Find the entry in |video|'s [=list of animation frame callbacks=] that is associated with the value |handle|.
  1. If there is such an entry, set its [=canceled=] boolean to <code>true</code> and remove it from |video|'s [=list of animation frame callbacks=].

## Procedures ## {#video-raf-procedures}

An {{HTMLVideoElement}} is considered to be an <dfn>associated video element</dfn> of a {{Document}}
|doc| if its {{ownerDocument}} attribute is the same as |doc|.

<div algorithm="video-raf-rendering-step">

Issue: This spec should eventually be merged into the HTML spec, and we should directly call [=run the
video animation frame callbacks=] from the [=update the rendering=] steps. This procedure describes
where and how to invoke the algorithm in the meantime.

When the [=update the rendering=] algorithm is invoked, run this new step:

+ For each [=fully active=] {{Document}} in |docs|, for each [=associated video element=] for that
  {{Document}}, [=run the video animation frame callbacks=] passing |now| as the timestamp.

immediately before this existing step:

+  "<i>For each [=fully active=] {{Document}} in |docs|, [=run the animation frame callbacks=] for that {{Document}}, passing in |now| as the timestamp</i>"

using the definitions for |docs| and |now| described in the [=update the rendering=] algorithm.

</div>

<div algorithm="run the video animation frame callbacks">

To <dfn>run the video animation frame callbacks</dfn> for a {{HTMLVideoElement}} |video| with a timestamp |now|, run the following steps:

1. If |video|'s [=list of animation frame callbacks=] is empty, abort these steps.
1. Let |metadata| be the {{VideoFrameMetadata}} dictionary built from |video|'s latest presented frame.
1. Let |presentedFrames| be the value of |metadata|'s {{presentedFrames}} field.
1. If the [=last presented frame indentifier=] is equal to |presentedFrames|, abort these steps.
1. Set the [=last presented frame indentifier=] to |presentedFrames|.
1. Let |callbacks| be the [=list of animation frame callbacks=].
1. Set |video|'s [=list of animation frame callbacks=] to be empty.
1. For each entry in |callbacks|
  1. If the entry's [=canceled=] boolean is <code>true</code>, continue to the next entry.
  1. [=Invoke=] the callback, passing |now| and |metadata| as arguments
  1. If an exception is thrown, [=report the exception=].

Note: There are **no strict timing guarantees** when it comes to how soon
{{VideoFrameRequestCallback|callbacks}} are run after a new video frame has been presented.
Consider the following scenario: a new frame is presented on the compositor thread, just as the user
agent aborts the [=run the video animation frame callbacks|algorithm=] above, when it confirms that
there are no new frames. We therefore won't run the {{VideoFrameRequestCallback|callbacks}} in the
*current* [=update the rendering|rendering steps=], and have to wait until the *next* [=update the
rendering|rendering steps=], one v-sync later. In that case, visual changes to a web page made from
within the delayed {{VideoFrameRequestCallback|callbacks}} will appear on-screen one v-sync after the
video frame does.<br/>
<br/>
Offering stricter guarantees would likely force implementers to add cross-thread synchronization, which might be detrimental to video playback performance.

</div>

# Security and Privacy Considerations # {#security-and-privacy}

This specification does not expose any new privacy-sensitive information. However, the location
correlation opportunities outlined in the Privacy and Security section of [[webrtc-stats]] also hold
true for this spec: {{captureTime}}, {{receiveTime}}, and {{rtpTimestamp}} expose network-layer
information which can be correlated to location information. E.g., reusing the same example,
{{captureTime}} and {{receiveTime}} can be used to estimate network end-to-end travel time, which can
give indication as to how far the peers are located, and can give some location information about a peer
if the location of the other peer is known. Since this information is already available via the
[[webrtc-stats|RTCStats]], this specification doesn't introduce any novel privacy considerations.

This specification might introduce some new GPU fingerprinting opportunities. {{elapsedProcessingTime}}
exposes some under-the-hood performance information about the video pipeline, which is otherwise
inaccessible to web developers. Using this information, one could correlate the performance of various
codecs and video sizes to a known GPU's profile. We therefore propose a resolution of 100Î¼s, which is
still useful for automated quality analysis, but doesn't offer any new sources of high resolution
information. Still, despite a coarse clock, one could exploit the significant performance differences
between hardware and software decoders to infer information about a GPU's features. For example, this
would make it easier to fingerprint the newest GPUs, which have hardware decoders for the latest
codecs, which don't yet have widespread hardware decoding support. However, rather than measuring the
profiles themselves, one could directly get equivalent information from getting the
{{MediaCapabilitiesInfo}}.

This specification also introduces some new timing information. {{timePresented}} and
{{expectedDisplayTime}} expose compositor timing information; {{captureTime}} and
{{receiveTime}} expose network timing information. The [=clock resolution=] of these fields should
therefore be coarse enough not to facilitate timing attacks.
