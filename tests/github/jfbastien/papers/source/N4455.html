<!doctype html><html lang="en">
 <head>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
  <meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
  <title>N4455RNone: No Sane Compiler Would Optimize Atomics</title>
<style data-fill-with="stylesheet">
  </style>
<style>
    table, th, td {
      border: 1px solid black;
      border-collapse: collapse;
      vertical-align: top;
    }
    th, td {
      border-left: none;
      border-right: none;
      padding: 0px 10px;
    }
    th {
      text-align: center;
    }

    del { background: #fcc; color: #000; text-decoration: line-through; }
    ins { background: #cfc; color: #000; }
    blockquote .highlight:not(.idl) { background: initial; margin: initial; padding: 0.5em }
    blockquote ul { background: inherit; }
    blockquote code.highlight:not(.idl) { padding: initial; }
    blockquote c-[a] { color: inherit; } /* Keyword.Declaration */
    blockquote c-[b] { color: inherit; } /* Keyword.Type */
    blockquote c-[c] { color: inherit; } /* Comment */
    blockquote c-[d] { color: inherit; } /* Comment.Multiline */
    blockquote c-[e] { color: inherit; } /* Name.Attribute */
    blockquote c-[f] { color: inherit; } /* Name.Tag */
    blockquote c-[g] { color: inherit; } /* Name.Variable */
    blockquote c-[k] { color: inherit; } /* Keyword */
    blockquote c-[l] { color: inherit; } /* Literal */
    blockquote c-[m] { color: inherit; } /* Literal.Number */
    blockquote c-[n] { color: inherit; } /* Name */
    blockquote c-[o] { color: inherit; } /* Operator */
    blockquote c-[p] { color: inherit; } /* Punctuation */
    blockquote c-[s] { color: inherit; } /* Literal.String */
    blockquote c-[t] { color: inherit; } /* Literal.String.Single */
    blockquote c-[u] { color: inherit; } /* Literal.String.Double */
    blockquote c-[cp] { color: inherit; } /* Comment.Preproc */
    blockquote c-[c1] { color: inherit; } /* Comment.Single */
    blockquote c-[cs] { color: inherit; } /* Comment.Special */
    blockquote c-[kc] { color: inherit; } /* Keyword.Constant */
    blockquote c-[kn] { color: inherit; } /* Keyword.Namespace */
    blockquote c-[kp] { color: inherit; } /* Keyword.Pseudo */
    blockquote c-[kr] { color: inherit; } /* Keyword.Reserved */
    blockquote c-[ld] { color: inherit; } /* Literal.Date */
    blockquote c-[nc] { color: inherit; } /* Name.Class */
    blockquote c-[no] { color: inherit; } /* Name.Constant */
    blockquote c-[nd] { color: inherit; } /* Name.Decorator */
    blockquote c-[ni] { color: inherit; } /* Name.Entity */
    blockquote c-[ne] { color: inherit; } /* Name.Exception */
    blockquote c-[nf] { color: inherit; } /* Name.Function */
    blockquote c-[nl] { color: inherit; } /* Name.Label */
    blockquote c-[nn] { color: inherit; } /* Name.Namespace */
    blockquote c-[py] { color: inherit; } /* Name.Property */
    blockquote c-[ow] { color: inherit; } /* Operator.Word */
    blockquote c-[mb] { color: inherit; } /* Literal.Number.Bin */
    blockquote c-[mf] { color: inherit; } /* Literal.Number.Float */
    blockquote c-[mh] { color: inherit; } /* Literal.Number.Hex */
    blockquote c-[mi] { color: inherit; } /* Literal.Number.Integer */
    blockquote c-[mo] { color: inherit; } /* Literal.Number.Oct */
    blockquote c-[sb] { color: inherit; } /* Literal.String.Backtick */
    blockquote c-[sc] { color: inherit; } /* Literal.String.Char */
    blockquote c-[sd] { color: inherit; } /* Literal.String.Doc */
    blockquote c-[se] { color: inherit; } /* Literal.String.Escape */
    blockquote c-[sh] { color: inherit; } /* Literal.String.Heredoc */
    blockquote c-[si] { color: inherit; } /* Literal.String.Interpol */
    blockquote c-[sx] { color: inherit; } /* Literal.String.Other */
    blockquote c-[sr] { color: inherit; } /* Literal.String.Regex */
    blockquote c-[ss] { color: inherit; } /* Literal.String.Symbol */
    blockquote c-[vc] { color: inherit; } /* Name.Variable.Class */
    blockquote c-[vg] { color: inherit; } /* Name.Variable.Global */
    blockquote c-[vi] { color: inherit; } /* Name.Variable.Instance */
    blockquote c-[il] { color: inherit; } /* Literal.Number.Integer.Long */
  </style>
  <link href="http://wg21.link/n4455" rel="canonical">
  <link href="https://isocpp.org/favicon.ico" rel="icon">
  <meta content="dark light" name="color-scheme">
<style>/* Boilerplate: style-autolinks */
.css.css, .property.property, .descriptor.descriptor {
    color: var(--a-normal-text);
    font-size: inherit;
    font-family: inherit;
}
.css::before, .property::before, .descriptor::before {
    content: "‘";
}
.css::after, .property::after, .descriptor::after {
    content: "’";
}
.property, .descriptor {
    /* Don't wrap property and descriptor names */
    white-space: nowrap;
}
.type { /* CSS value <type> */
    font-style: italic;
}
pre .property::before, pre .property::after {
    content: "";
}
[data-link-type="property"]::before,
[data-link-type="propdesc"]::before,
[data-link-type="descriptor"]::before,
[data-link-type="value"]::before,
[data-link-type="function"]::before,
[data-link-type="at-rule"]::before,
[data-link-type="selector"]::before,
[data-link-type="maybe"]::before {
    content: "‘";
}
[data-link-type="property"]::after,
[data-link-type="propdesc"]::after,
[data-link-type="descriptor"]::after,
[data-link-type="value"]::after,
[data-link-type="function"]::after,
[data-link-type="at-rule"]::after,
[data-link-type="selector"]::after,
[data-link-type="maybe"]::after {
    content: "’";
}

[data-link-type].production::before,
[data-link-type].production::after,
.prod [data-link-type]::before,
.prod [data-link-type]::after {
    content: "";
}

[data-link-type=element],
[data-link-type=element-attr] {
    font-family: Menlo, Consolas, "DejaVu Sans Mono", monospace;
    font-size: .9em;
}
[data-link-type=element]::before { content: "<" }
[data-link-type=element]::after  { content: ">" }

[data-link-type=biblio] {
    white-space: pre;
}

@media (prefers-color-scheme: dark) {
    :root {
        --selflink-text: black;
        --selflink-bg: silver;
        --selflink-hover-text: white;
    }
}
</style>
<style>/* Boilerplate: style-colors */
/* Any --*-text not paired with a --*-bg is assumed to have a transparent bg */
:root {
    color-scheme: light dark;

    --text: black;
    --bg: white;

    --unofficial-watermark: url(https://www.w3.org/StyleSheets/TR/2016/logos/UD-watermark);

    --logo-bg: #1a5e9a;
    --logo-active-bg: #c00;
    --logo-text: white;

    --tocnav-normal-text: #707070;
    --tocnav-normal-bg: var(--bg);
    --tocnav-hover-text: var(--tocnav-normal-text);
    --tocnav-hover-bg: #f8f8f8;
    --tocnav-active-text: #c00;
    --tocnav-active-bg: var(--tocnav-normal-bg);

    --tocsidebar-text: var(--text);
    --tocsidebar-bg: #f7f8f9;
    --tocsidebar-shadow: rgba(0,0,0,.1);
    --tocsidebar-heading-text: hsla(203,20%,40%,.7);

    --toclink-text: var(--text);
    --toclink-underline: #3980b5;
    --toclink-visited-text: var(--toclink-text);
    --toclink-visited-underline: #054572;

    --heading-text: #005a9c;

    --hr-text: var(--text);

    --algo-border: #def;

    --del-text: red;
    --del-bg: transparent;
    --ins-text: #080;
    --ins-bg: transparent;

    --a-normal-text: #034575;
    --a-normal-underline: #bbb;
    --a-visited-text: var(--a-normal-text);
    --a-visited-underline: #707070;
    --a-hover-bg: rgba(75%, 75%, 75%, .25);
    --a-active-text: #c00;
    --a-active-underline: #c00;

    --blockquote-border: silver;
    --blockquote-bg: transparent;
    --blockquote-text: currentcolor;

    --issue-border: #e05252;
    --issue-bg: #fbe9e9;
    --issue-text: var(--text);
    --issueheading-text: #831616;

    --example-border: #e0cb52;
    --example-bg: #fcfaee;
    --example-text: var(--text);
    --exampleheading-text: #574b0f;

    --note-border: #52e052;
    --note-bg: #e9fbe9;
    --note-text: var(--text);
    --noteheading-text: hsl(120, 70%, 30%);
    --notesummary-underline: silver;

    --assertion-border: #aaa;
    --assertion-bg: #eee;
    --assertion-text: black;

    --advisement-border: orange;
    --advisement-bg: #fec;
    --advisement-text: var(--text);
    --advisementheading-text: #b35f00;

    --warning-border: red;
    --warning-bg: hsla(40,100%,50%,0.95);
    --warning-text: var(--text);

    --amendment-border: #330099;
    --amendment-bg: #F5F0FF;
    --amendment-text: var(--text);
    --amendmentheading-text: #220066;

    --def-border: #8ccbf2;
    --def-bg: #def;
    --def-text: var(--text);
    --defrow-border: #bbd7e9;

    --datacell-border: silver;

    --indexinfo-text: #707070;

    --indextable-hover-text: black;
    --indextable-hover-bg: #f7f8f9;

    --outdatedspec-bg: rgba(0, 0, 0, .5);
    --outdatedspec-text: black;
    --outdated-bg: maroon;
    --outdated-text: white;
    --outdated-shadow: red;

    --editedrec-bg: darkorange;
}

@media (prefers-color-scheme: dark) {
    :root {
        --text: #ddd;
        --bg: black;

        --unofficial-watermark: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='400' height='400'%3E%3Cg fill='%23100808' transform='translate(200 200) rotate(-45) translate(-200 -200)' stroke='%23100808' stroke-width='3'%3E%3Ctext x='50%25' y='220' style='font: bold 70px sans-serif; text-anchor: middle; letter-spacing: 6px;'%3EUNOFFICIAL%3C/text%3E%3Ctext x='50%25' y='305' style='font: bold 70px sans-serif; text-anchor: middle; letter-spacing: 6px;'%3EDRAFT%3C/text%3E%3C/g%3E%3C/svg%3E");

        --logo-bg: #1a5e9a;
        --logo-active-bg: #c00;
        --logo-text: white;

        --tocnav-normal-text: #999;
        --tocnav-normal-bg: var(--bg);
        --tocnav-hover-text: var(--tocnav-normal-text);
        --tocnav-hover-bg: #080808;
        --tocnav-active-text: #f44;
        --tocnav-active-bg: var(--tocnav-normal-bg);

        --tocsidebar-text: var(--text);
        --tocsidebar-bg: #080808;
        --tocsidebar-shadow: rgba(255,255,255,.1);
        --tocsidebar-heading-text: hsla(203,20%,40%,.7);

        --toclink-text: var(--text);
        --toclink-underline: #6af;
        --toclink-visited-text: var(--toclink-text);
        --toclink-visited-underline: #054572;

        --heading-text: #8af;

        --hr-text: var(--text);

        --algo-border: #456;

        --del-text: #f44;
        --del-bg: transparent;
        --ins-text: #4a4;
        --ins-bg: transparent;

        --a-normal-text: #6af;
        --a-normal-underline: #555;
        --a-visited-text: var(--a-normal-text);
        --a-visited-underline: var(--a-normal-underline);
        --a-hover-bg: rgba(25%, 25%, 25%, .2);
        --a-active-text: #f44;
        --a-active-underline: var(--a-active-text);

        --borderedblock-bg: rgba(255, 255, 255, .05);

        --blockquote-border: silver;
        --blockquote-bg: var(--borderedblock-bg);
        --blockquote-text: currentcolor;

        --issue-border: #e05252;
        --issue-bg: var(--borderedblock-bg);
        --issue-text: var(--text);
        --issueheading-text: hsl(0deg, 70%, 70%);

        --example-border: hsl(50deg, 90%, 60%);
        --example-bg: var(--borderedblock-bg);
        --example-text: var(--text);
        --exampleheading-text: hsl(50deg, 70%, 70%);

        --note-border: hsl(120deg, 100%, 35%);
        --note-bg: var(--borderedblock-bg);
        --note-text: var(--text);
        --noteheading-text: hsl(120, 70%, 70%);
        --notesummary-underline: silver;

        --assertion-border: #444;
        --assertion-bg: var(--borderedblock-bg);
        --assertion-text: var(--text);

        --advisement-border: orange;
        --advisement-bg: #222218;
        --advisement-text: var(--text);
        --advisementheading-text: #f84;

        --warning-border: red;
        --warning-bg: hsla(40,100%,20%,0.95);
        --warning-text: var(--text);

        --amendment-border: #330099;
        --amendment-bg: #080010;
        --amendment-text: var(--text);
        --amendmentheading-text: #cc00ff;

        --def-border: #8ccbf2;
        --def-bg: #080818;
        --def-text: var(--text);
        --defrow-border: #136;

        --datacell-border: silver;

        --indexinfo-text: #aaa;

        --indextable-hover-text: var(--text);
        --indextable-hover-bg: #181818;

        --outdatedspec-bg: rgba(255, 255, 255, .5);
        --outdatedspec-text: black;
        --outdated-bg: maroon;
        --outdated-text: white;
        --outdated-shadow: red;

        --editedrec-bg: darkorange;
    }
    /* In case a transparent-bg image doesn't expect to be on a dark bg,
       which is quite common in practice... */
    img { background: white; }
}
</style>
<style>/* Boilerplate: style-counters */
body {
    counter-reset: example figure issue;
}
.issue {
    counter-increment: issue;
}
.issue:not(.no-marker)::before {
    content: "Issue " counter(issue);
}

.example {
    counter-increment: example;
}
.example:not(.no-marker)::before {
    content: "Example " counter(example);
}
.invalid.example:not(.no-marker)::before,
.illegal.example:not(.no-marker)::before {
    content: "Invalid Example" counter(example);
}

figcaption {
    counter-increment: figure;
}
figcaption:not(.no-marker)::before {
    content: "Figure " counter(figure) " ";
}
</style>
<style>/* Boilerplate: style-issues */
a[href].issue-return {
    float: right;
    float: inline-end;
    color: var(--issueheading-text);
    font-weight: bold;
    text-decoration: none;
}
</style>
<style>/* Boilerplate: style-md-lists */
/* This is a weird hack for me not yet following the commonmark spec
   regarding paragraph and lists. */
[data-md] > :first-child {
    margin-top: 0;
}
[data-md] > :last-child {
    margin-bottom: 0;
}
</style>
<style>/* Boilerplate: style-selflinks */
:root {
    --selflink-text: white;
    --selflink-bg: gray;
    --selflink-hover-text: black;
}
.heading, .issue, .note, .example, li, dt {
    position: relative;
}
a.self-link {
    position: absolute;
    top: 0;
    left: calc(-1 * (3.5rem - 26px));
    width: calc(3.5rem - 26px);
    height: 2em;
    text-align: center;
    border: none;
    transition: opacity .2s;
    opacity: .5;
}
a.self-link:hover {
    opacity: 1;
}
.heading > a.self-link {
    font-size: 83%;
}
.example > a.self-link,
.note > a.self-link,
.issue > a.self-link {
    /* These blocks are overflow:auto, so positioning outside
       doesn't work. */
    left: auto;
    right: 0;
}
li > a.self-link {
    left: calc(-1 * (3.5rem - 26px) - 2em);
}
dfn > a.self-link {
    top: auto;
    left: auto;
    opacity: 0;
    width: 1.5em;
    height: 1.5em;
    background: var(--selflink-bg);
    color: var(--selflink-text);
    font-style: normal;
    transition: opacity .2s, background-color .2s, color .2s;
}
dfn:hover > a.self-link {
    opacity: 1;
}
dfn > a.self-link:hover {
    color: var(--selflink-hover-text);
}

a.self-link::before            { content: "¶"; }
.heading > a.self-link::before { content: "§"; }
dfn > a.self-link::before      { content: "#"; }
</style>
 <body class="h-entry">
  <div class="head">
   <p data-fill-with="logo"></p>
   <h1 class="p-name no-ref" id="title">N4455RNone<br>No Sane Compiler Would Optimize Atomics</h1>
   <h2 class="no-num no-toc no-ref heading settled" id="profile-and-date"><span class="content">Published Proposal, <time class="dt-updated" datetime="1970-01-01">1970-01-01</time></span></h2>
   <div data-fill-with="spec-metadata">
    <dl>
     <dt>This version:
     <dd><a class="u-url" href="http://wg21.link/n4455">http://wg21.link/n4455</a>
     <dt class="editor">Author:
     <dd class="editor p-author h-card vcard"><a class="p-name fn u-email email" href="mailto:jfb@google.com">JF Bastien</a> (<span class="p-org org">Google</span>)
     <dt>Project:
     <dd>ISO/IEC 14882 Programming Languages — C++, ISO/IEC JTC1/SC22/WG21
    </dl>
   </div>
   <div data-fill-with="warning"></div>
   <hr title="Separator for header">
  </div>
  <div class="p-summary" data-fill-with="abstract">
   <h2 class="no-num no-toc no-ref heading settled" id="abstract"><span class="content">Abstract</span><a class="self-link" href="#abstract"></a></h2>
   <p>False. Compilers do optimize atomics, memory accesses around atomics, and utilize architecture-specific knowledge. This paper illustrates a few such optimizations, and discusses their implications.</p>
  </div>
  <nav data-fill-with="table-of-contents" id="toc">
   <h2 class="no-num no-toc no-ref heading settled" id="contents"><span class="content">Table of Contents</span></h2>
   <ol class="toc" role="directory">
    <li>
     <a href="#Samples"><span class="secno">1</span> <span class="content">Sample Optimizations</span></a>
     <ol class="toc">
      <li><a href="#opt-on"><span class="secno">1.1</span> <span class="content">Optimizations on Atomics</span></a>
      <li><a href="#opt-around"><span class="secno">1.2</span> <span class="content">Optimizations Around Atomics</span></a>
      <li><a href="#mutex"><span class="secno">1.3</span> <span class="content">Mutex: Safer than Atomics?</span></a>
      <li><a href="#opt-without"><span class="secno">1.4</span> <span class="content">Optimizations without Atomics</span></a>
      <li><a href="#arch"><span class="secno">1.5</span> <span class="content">Architecture and Implementation Specific Optimizations</span></a>
      <li><a href="#volatile"><span class="secno">1.6</span> <span class="content">Volatility</span></a>
     </ol>
    <li>
     <a href="#takeaways"><span class="secno">2</span> <span class="content">Takeaways</span></a>
     <ol class="toc">
      <li><a href="#committee"><span class="secno">2.1</span> <span class="content">For the Standards Committee</span></a>
      <li><a href="#devs"><span class="secno">2.2</span> <span class="content">For Developers</span></a>
      <li><a href="#hw"><span class="secno">2.3</span> <span class="content">For Hardware vendors</span></a>
      <li><a href="#compiler"><span class="secno">2.4</span> <span class="content">For Compiler Writers</span></a>
     </ol>
    <li><a href="#acknowledgement"><span class="secno">3</span> <span class="content">Acknowledgement</span></a>
   </ol>
  </nav>
  <main>
   <h2 class="heading settled" data-level="1" id="Samples"><span class="secno">1. </span><span class="content">Sample Optimizations</span><a class="self-link" href="#Samples"></a></h2>
   <p>We list optimizations that are either implemented in LLVM, or will be readily
implemented. A general rule to keep in mind is that the compiler performs many
of its optimizations on and around atomics based on the <em>as-if</em> rule. This implies that the compiler can make operations <strong>more</strong> atomic as long as it doesn’t violate forward progress requirements, and can make
them <strong>less</strong> atomic as long as it doesn’t add non-benign race
which weren’t already present in the original program. Put another way, correct
programs must work under all executions an implementation is allowed to create.</p>
   <h3 class="heading settled" data-level="1.1" id="opt-on"><span class="secno">1.1. </span><span class="content">Optimizations on Atomics</span><a class="self-link" href="#opt-on"></a></h3>
   <p>Atomics themselves can be optimized. A non-contentious example is constant
propagation into atomics without other intervening atomics:</p>
<pre class="highlight"><c- b>void</c-> <c- nf>inc</c-><c- p>(</c-><c- n>std</c-><c- o>::</c-><c- n>atomic</c-><c- o>&lt;</c-><c- b>int</c-><c- o>></c-> <c- o>*</c-><c- n>y</c-><c- p>)</c-> <c- p>{</c->
  <c- o>*</c-><c- n>y</c-> <c- o>+=</c-> <c- mi>1</c-><c- p>;</c->
<c- p>}</c->

<c- n>std</c-><c- o>::</c-><c- n>atomic</c-><c- o>&lt;</c-><c- b>int</c-><c- o>></c-> <c- n>x</c-><c- p>;</c->
<c- b>void</c-> <c- nf>two</c-><c- p>()</c-> <c- p>{</c->
  <c- n>inc</c-><c- p>(</c-><c- o>&amp;</c-><c- n>x</c-><c- p>);</c->
  <c- n>inc</c-><c- p>(</c-><c- o>&amp;</c-><c- n>x</c-><c- p>);</c->
<c- p>}</c->
</pre>
   <p>Becomes:</p>
<pre class="highlight"><c- n>std</c-><c- o>::</c-><c- n>atomic</c-><c- o>&lt;</c-><c- b>int</c-><c- o>></c-> <c- n>x</c-><c- p>;</c->
<c- b>void</c-> <c- nf>two</c-><c- p>()</c-> <c- p>{</c->
  <c- n>x</c-> <c- o>+=</c-> <c- mi>2</c-><c- p>;</c->
<c- p>}</c->
</pre>
   <p>The above optimization adds atomicity but cannot hinder forward progress, and is
therefore correct. This leads to further optimizations such as using the locked <code class="highlight"><c- n>inc</c-></code>/<code class="highlight"><c- n>dec</c-></code> instructions instead of locked <code class="highlight"><c- n>add</c-></code>/<code class="highlight"><c- n>sub</c-></code> when adding/subtracting <code class="highlight"><c- mi>1</c-></code> to an
atomic on x86:</p>
<pre class="highlight"><c- n>std</c-><c- o>::</c-><c- n>atomic</c-><c- o>&lt;</c-><c- b>int</c-><c- o>></c-> <c- n>x</c-><c- p>;</c->
<c- b>void</c-> <c- nf>inc</c-><c- p>(</c-><c- b>int</c-> <c- n>val</c-><c- p>)</c-> <c- p>{</c->
  <c- n>x</c-> <c- o>+=</c-> <c- mi>1</c-><c- p>;</c->
  <c- n>x</c-> <c- o>+=</c-> <c- n>val</c-><c- p>;</c->
<c- p>}</c->
</pre>
   <p>Becomes:</p>
<pre class="highlight"><c- nl>_Z3inci:</c->
  <c- e>lock</c-> <c- nf>incl</c-> <c- no>x</c-><c- p>(</c-><c- g>%rip</c-><c- p>)</c->
  <c- e>lock</c-> <c- nf>addl</c-> <c- g>%edi</c-><c- p>,</c-> <c- no>x</c-><c- p>(</c-><c- g>%rip</c-><c- p>)</c->
  <c- nf>retq</c->
</pre>
   <p>In a similar vein, some opportunities for strength reduction will show up
because non-trivial code gets inlined which then exposes fairly silly code, such
as in the following trivial example:</p>
<pre class="highlight"><c- k>template</c-><c- o>&lt;</c-><c- k>typename</c-> <c- nc>T</c-><c- o>></c->
<c- b>bool</c-> <c- n>silly</c-><c- p>(</c-><c- n>std</c-><c- o>::</c-><c- n>atomic</c-><c- o>&lt;</c-><c- n>T</c-><c- o>></c-> <c- o>*</c-><c- n>x</c-><c- p>,</c-> <c- n>T</c-> <c- n>expected</c-><c- p>,</c-> <c- n>T</c-> <c- n>desired</c-><c- p>)</c-> <c- p>{</c->
  <c- n>x</c-><c- o>-></c-><c- n>compare_exchange_strong</c-><c- p>(</c-><c- n>expected</c-><c- p>,</c-> <c- n>desired</c-><c- p>);</c-> <c- c1>// Inlined.</c->
  <c- k>return</c-> <c- n>expected</c-> <c- o>==</c-> <c- n>desired</c-><c- p>;</c->
<c- p>}</c->
</pre>
   <p>Becomes:</p>
<pre class="highlight"><c- k>template</c-><c- o>&lt;</c-><c- k>typename</c-> <c- nc>T</c-><c- o>></c->
<c- b>bool</c-> <c- n>silly</c-><c- p>(</c-><c- n>std</c-><c- o>::</c-><c- n>atomic</c-><c- o>&lt;</c-><c- n>T</c-><c- o>></c-> <c- o>*</c-><c- n>x</c-><c- p>,</c-> <c- n>T</c-> <c- n>expected</c-><c- p>,</c-> <c- n>T</c-> <c- n>desired</c-><c- p>)</c-> <c- p>{</c->
  <c- k>return</c-> <c- n>x</c-><c- o>-></c-><c- n>compare_exchange_strong</c-><c- p>(</c-><c- n>expected</c-><c- p>,</c-> <c- n>desired</c-><c- p>);</c->
<c- p>}</c->
</pre>
   <p>The following works for any memory order but <code class="highlight"><c- n>release</c-></code> and <code class="highlight"><c- n>acq_rel</c-></code>:</p>
<pre class="highlight"><c- k>template</c-><c- o>&lt;</c-><c- k>typename</c-> <c- nc>T</c-><c- o>></c->
<c- b>bool</c-> <c- n>optme</c-><c- p>(</c-><c- n>std</c-><c- o>::</c-><c- n>atomic</c-><c- o>&lt;</c-><c- n>T</c-><c- o>></c-> <c- o>*</c-><c- n>x</c-><c- p>,</c-> <c- n>T</c-> <c- n>desired</c-><c- p>)</c-> <c- p>{</c->
  <c- n>T</c-> <c- n>expected</c-> <c- o>=</c-> <c- n>desired</c-><c- p>;</c->
  <c- k>return</c-> <c- n>x</c-><c- o>-></c-><c- n>compare_exchange_strong</c-><c- p>(</c-><c- n>expected</c-><c- p>,</c-> <c- n>desired</c->
    <c- n>std</c-><c- o>::</c-><c- n>memory_order_seq_cst</c-><c- p>,</c-> <c- n>std</c-><c- o>::</c-><c- n>memory_order_relaxed</c-><c- p>);</c->
<c- p>}</c->
</pre>
   <p>Becomes:</p>
<pre class="highlight"><c- k>template</c-><c- o>&lt;</c-><c- k>typename</c-> <c- nc>T</c-><c- o>></c->
<c- b>bool</c-> <c- n>optme</c-><c- p>(</c-><c- n>std</c-><c- o>::</c-><c- n>atomic</c-><c- o>&lt;</c-><c- n>T</c-><c- o>></c-> <c- o>*</c-><c- n>x</c-><c- p>,</c-> <c- n>T</c-> <c- n>desired</c-><c- p>)</c-> <c- p>{</c->
  <c- k>return</c-> <c- n>x</c-><c- o>-></c-><c- n>load</c-><c- p>(</c-><c- n>std</c-><c- o>::</c-><c- n>memory_order_seq_cst</c-><c- p>)</c-> <c- o>==</c-> <c- n>desired</c-><c- p>;</c->
<c- p>}</c->
</pre>
   <p>The above optimization may require that the compiler mark the transformed load
as a <em>release sequence</em> as defined in section 1.10 of the C++ standard.</p>
   <p>Similarly, while keeping the resulting memory order stronger or equal to the
individual ones, the following can occur:</p>
<pre class="highlight"><c- k>template</c-><c- o>&lt;</c-><c- k>typename</c-> <c- nc>T</c-><c- o>></c->
<c- n>T</c-> <c- n>optmetoo</c-><c- p>(</c-><c- n>std</c-><c- o>::</c-><c- n>atomic</c-><c- o>&lt;</c-><c- n>T</c-><c- o>></c-> <c- o>*</c-><c- n>x</c-><c- p>,</c-> <c- n>T</c-> <c- n>y</c-><c- p>)</c-> <c- p>{</c->
  <c- n>T</c-> <c- n>z</c-> <c- o>=</c-> <c- n>x</c-><c- o>-></c-><c- n>load</c-><c- p>();</c->
  <c- n>x</c-><c- o>-></c-><c- n>store</c-><c- p>(</c-><c- n>y</c-><c- p>);</c->
  <c- k>return</c-> <c- n>z</c-><c- p>;</c->
<c- p>}</c->
</pre>
   <p>Becomes:</p>
<pre class="highlight"><c- k>template</c-><c- o>&lt;</c-><c- k>typename</c-> <c- nc>T</c-><c- o>></c->
<c- n>T</c-> <c- n>optmetoo</c-><c- p>(</c-><c- n>std</c-><c- o>::</c-><c- n>atomic</c-><c- o>&lt;</c-><c- n>T</c-><c- o>></c-> <c- o>*</c-><c- n>x</c-><c- p>,</c-> <c- n>T</c-> <c- n>y</c-><c- p>)</c-> <c- p>{</c->
  <c- k>return</c-> <c- n>x</c-><c- o>-></c-><c- n>exchange</c-><c- p>(</c-><c- n>y</c-><c- p>);</c->
<c- p>}</c->
</pre>
   <p>This may not always pay off! In particular, architectures with weaker memory
models may benefit from having write-after-read operations to the same location
instead of having an atomic exchange.</p>
   <p>Other simple optimizations can also occur because of inlining and constant
propagation such as turning <code class="highlight"><c- n>atomic</c-><c- o>&lt;</c-><c- n>T</c-><c- o>>::</c-><c- n>fetch_and</c-><c- p>(</c-><c- o>~</c-><c- p>(</c-><c- n>T</c-><c- p>)</c-><c- mi>0</c-><c- p>)</c-></code> into <code class="highlight"><c- n>atomic</c-><c- o>&lt;</c-><c- n>T</c-><c- o>>::</c-><c- n>load</c-><c- p>()</c-></code>. The same applies for <code class="highlight"><c- n>fetch_or</c-><c- p>(</c-><c- mi>0</c-><c- p>)</c-></code> and <code class="highlight"><c- n>fetch_xor</c-><c- p>(</c-><c- mi>0</c-><c- p>)</c-></code>, as well as <code class="highlight"><c- n>fetch_and</c-><c- p>(</c-><c- mi>0</c-><c- p>)</c-></code> becoming <code class="highlight"><c- n>store</c-><c- p>(</c-><c- mi>0</c-><c- p>)</c-></code>.</p>
   <p>As a slightly different example, the value for <code class="highlight"><c- n>std</c-><c- o>::</c-><c- n>is_lock_free</c-></code> can be determined at compile time for some architectures, but for others the
compiler can’t know the value for all sub-architectures and cannot return a
compile-time constant. The compiler may be given a specific sub-architecture
flag to work around this (restricting which machines the code will execute
correctly on) or must defer to feature detection followed by patching when the
program is loaded. This is the case, for example, for x86’s <code class="highlight"><c- n>LOCK</c-> <c- n>CMPXCHG16B</c-></code> instruction which is used to implement lock-free 16-byte
operations.</p>
   <p>These optimizations aren’t traditionally performed when using inline assembly
and showcases the strengths of hoisting abstractions to the language level.</p>
   <p>The reader for <a href="https://en.wikipedia.org/wiki/Seqlock">seqlock</a> bounds ticket acquisition and release with a load and a fence. This lets the
data reads get reordered in-between ticket acquire/release by using <code class="highlight"><c- n>relaxed</c-></code> memory ordering for data. The algorithm retries if the
ticket changed or data was being modified by the writer:</p>
<pre class="highlight"><c- n>std</c-><c- o>::</c-><c- n>tuple</c-><c- o>&lt;</c-><c- n>T</c-><c- p>,</c-> <c- n>T</c-><c- o>></c-> <c- n>reader</c-><c- p>()</c-> <c- p>{</c->
  <c- n>T</c-> <c- n>d1</c-><c- p>,</c-> <c- n>d2</c-><c- p>;</c->
  <c- b>unsigned</c-> <c- n>seq0</c-><c- p>,</c-> <c- n>seq1</c-><c- p>;</c->
  <c- k>do</c-> <c- p>{</c->
    <c- n>seq0</c-> <c- o>=</c-> <c- n>seq</c-><c- p>.</c-><c- n>load</c-><c- p>(</c-><c- n>std</c-><c- o>::</c-><c- n>memory_order_acquire</c-><c- p>);</c->
    <c- n>d1</c-> <c- o>=</c-> <c- n>data1</c-><c- p>.</c-><c- n>load</c-><c- p>(</c-><c- n>std</c-><c- o>::</c-><c- n>memory_order_relaxed</c-><c- p>);</c->
    <c- n>d2</c-> <c- o>=</c-> <c- n>data2</c-><c- p>.</c-><c- n>load</c-><c- p>(</c-><c- n>std</c-><c- o>::</c-><c- n>memory_order_relaxed</c-><c- p>);</c->
    <c- n>std</c-><c- o>::</c-><c- n>atomic_thread_fence</c-><c- p>(</c-><c- n>std</c-><c- o>::</c-><c- n>memory_order_acquire</c-><c- p>);</c->
    <c- n>seq1</c-> <c- o>=</c-> <c- n>seq</c-><c- p>.</c-><c- n>load</c-><c- p>(</c-><c- n>std</c-><c- o>::</c-><c- n>memory_order_relaxed</c-><c- p>);</c->
  <c- p>}</c-> <c- k>while</c-> <c- p>(</c-><c- n>seq0</c-> <c- o>!=</c-> <c- n>seq1</c-> <c- o>||</c-> <c- n>seq0</c-> <c- o>&amp;</c-> <c- mi>1</c-><c- p>);</c->
  <c- k>return</c-> <c- p>{</c-><c- n>d1</c-><c- p>,</c-> <c- n>d2</c-><c- p>};</c->
<c- p>}</c->

<c- b>void</c-> <c- n>writer</c-><c- p>(</c-><c- n>T</c-> <c- n>d1</c-><c- p>,</c-> <c- n>T</c-> <c- n>d2</c-><c- p>)</c-> <c- p>{</c->
  <c- b>unsigned</c-> <c- n>seq0</c-> <c- o>=</c-> <c- n>seq</c-><c- p>.</c-><c- n>load</c-><c- p>(</c-><c- n>std</c-><c- o>::</c-><c- n>memory_order_relaxed</c-><c- p>);</c->
  <c- n>seq</c-><c- p>.</c-><c- n>store</c-><c- p>(</c-><c- n>seq0</c-> <c- o>+</c-> <c- mi>1</c-><c- p>,</c-> <c- n>std</c-><c- o>::</c-><c- n>memory_order_relaxed</c-><c- p>);</c->
  <c- n>data1</c-><c- p>.</c-><c- n>store</c-><c- p>(</c-><c- n>d1</c-><c- p>,</c-> <c- n>std</c-><c- o>::</c-><c- n>memory_order_release</c-><c- p>);</c->
  <c- n>data2</c-><c- p>.</c-><c- n>store</c-><c- p>(</c-><c- n>d2</c-><c- p>,</c-> <c- n>std</c-><c- o>::</c-><c- n>memory_order_release</c-><c- p>);</c->
  <c- n>seq</c-><c- p>.</c-><c- n>store</c-><c- p>(</c-><c- n>seq0</c-> <c- o>+</c-> <c- mi>2</c-><c- p>,</c-> <c- n>std</c-><c- o>::</c-><c- n>memory_order_release</c-><c- p>);</c->
<c- p>}</c->
</pre>
   <p>The reader’s last ticket load effectively act as a <code class="highlight"><c- n>release</c-></code> load,
which doesn’t exist in the current memory model but would better express the
intent of the code while allowing subsequent operations to be moved into the
critical section if profitable. Hans Boehm <a href="http://www.hpl.hp.com/techreports/2012/HPL-2012-68.pdf">suggests</a> using
a <code class="highlight"><c- n>release</c-></code> fetch-add of zero, and shows that on x86 the code can be
written as follows:</p>
<pre class="highlight"><c- n>T</c-> <c- n>d1</c-><c- p>,</c-> <c- n>d2</c-><c- p>;</c->
<c- b>unsigned</c-> <c- n>seq0</c-><c- p>,</c-> <c- n>seq1</c-><c- p>;</c->
<c- k>do</c-> <c- p>{</c->
  <c- n>seq0</c-> <c- o>=</c-> <c- n>seq</c-><c- p>.</c-><c- n>load</c-><c- p>(</c-><c- n>std</c-><c- o>::</c-><c- n>memory_order_acquire</c-><c- p>);</c->
  <c- n>d1</c-> <c- o>=</c-> <c- n>data1</c-><c- p>.</c-><c- n>load</c-><c- p>(</c-><c- n>std</c-><c- o>::</c-><c- n>memory_order_relaxed</c-><c- p>);</c->
  <c- n>d2</c-> <c- o>=</c-> <c- n>data2</c-><c- p>.</c-><c- n>load</c-><c- p>(</c-><c- n>std</c-><c- o>::</c-><c- n>memory_order_relaxed</c-><c- p>);</c->
  <c- n>seq1</c-> <c- o>=</c-> <c- n>seq</c-><c- p>.</c-><c- n>fetch_add</c-><c- p>(</c-><c- mi>0</c-><c- p>,</c-> <c- n>std</c-><c- o>::</c-><c- n>memory_order_release</c-><c- p>);</c->
<c- p>}</c-> <c- k>while</c-> <c- p>(</c-><c- n>seq0</c-> <c- o>!=</c-> <c- n>seq1</c-> <c- o>||</c-> <c- n>seq0</c-> <c- o>&amp;</c-> <c- mi>1</c-><c- p>);</c->
</pre>
   <p>This rewritten code then generates the following x86 assembly:</p>
<pre class="highlight"><c- nl>.LBB0_1:</c->
      <c- nf>movl</c->    <c- no>seq</c-><c- p>(</c-><c- g>%rip</c-><c- p>),</c-> <c- g>%esi</c->
      <c- nf>movl</c->    <c- no>data1</c-><c- p>(</c-><c- g>%rip</c-><c- p>),</c-> <c- g>%ecx</c->
      <c- nf>movl</c->    <c- no>data2</c-><c- p>(</c-><c- g>%rip</c-><c- p>),</c-> <c- g>%eax</c->
      <c- nf>mfence</c->
      <c- nf>movl</c->    <c- no>seq</c-><c- p>(</c-><c- g>%rip</c-><c- p>),</c-> <c- g>%edi</c->
      <c- nf>movl</c->    <c- g>%esi</c-><c- p>,</c-> <c- g>%edx</c->
      <c- nf>andl</c->    <c- no>$1</c-><c- p>,</c-> <c- g>%edx</c->
      <c- nf>cmpl</c->    <c- g>%edi</c-><c- p>,</c-> <c- g>%esi</c->
      <c- nf>jne</c->     <c- no>.LBB0_1</c->
      <c- nf>testl</c->   <c- g>%edx</c-><c- p>,</c-> <c- g>%edx</c->
      <c- nf>jne</c->     <c- no>.LBB0_1</c->
</pre>
   <p>This x86 assembly reduces contention by replacing <code class="highlight"><c- n>fetch_add</c-></code>—an
instruction requiring exclusive cache line access—to a simple <code class="highlight"><c- n>movl</c-></code>. This optimization is currently only known to be correct on
x86, is probably correct for other architectures, and is <a href="https://reviews.llvm.org/D5091">currently implemented
in LLVM</a>.</p>
   <p>Similar to the above <code class="highlight"><c- n>release</c-></code> fetch-add of zero serving as a <code class="highlight"><c- n>release</c-></code> load, one could also use an <code class="highlight"><c- n>acquire</c-></code> exchange
when an <code class="highlight"><c- n>acquire</c-></code> store is desired.</p>
   <p>Traditional compiler optimizations, such as dead store elimination, can be
performed on atomic operations, even sequentially consistent ones. Optimizers
have to be careful to avoid doing so across synchronization points because
another thread of execution can observe or modify memory, which means that the
traditional optimizations have to consider more intervening instructions than
they usually would when considering optimizations to atomic operations. In the
case of dead store elimination it isn’t sufficient to prove that an atomic store
post-dominates and aliases another to eliminate the other store.</p>
   <p>A trickier example is fusion of <code class="highlight"><c- n>relaxed</c-></code> atomic operations, even
when interleaved:</p>
<pre class="highlight"><c- n>std</c-><c- o>::</c-><c- n>atomic</c-><c- o>&lt;</c-><c- b>int</c-><c- o>></c-> <c- n>x</c-><c- p>,</c-> <c- n>y</c-><c- p>;</c->
<c- b>void</c-> <c- nf>relaxed</c-><c- p>()</c-> <c- p>{</c->
  <c- n>x</c-><c- p>.</c-><c- n>fetch_add</c-><c- p>(</c-><c- mi>1</c-><c- p>,</c-> <c- n>std</c-><c- o>::</c-><c- n>memory_order_relaxed</c-><c- p>);</c->
  <c- n>y</c-><c- p>.</c-><c- n>fetch_add</c-><c- p>(</c-><c- mi>1</c-><c- p>,</c-> <c- n>std</c-><c- o>::</c-><c- n>memory_order_relaxed</c-><c- p>);</c->
  <c- n>x</c-><c- p>.</c-><c- n>fetch_add</c-><c- p>(</c-><c- mi>1</c-><c- p>,</c-> <c- n>std</c-><c- o>::</c-><c- n>memory_order_relaxed</c-><c- p>);</c->
  <c- n>y</c-><c- p>.</c-><c- n>fetch_add</c-><c- p>(</c-><c- mi>1</c-><c- p>,</c-> <c- n>std</c-><c- o>::</c-><c- n>memory_order_relaxed</c-><c- p>);</c->
<c- p>}</c->
</pre>
   <p>Becomes:</p>
<pre class="highlight"><c- n>std</c-><c- o>::</c-><c- n>atomic</c-><c- o>&lt;</c-><c- b>int</c-><c- o>></c-> <c- n>x</c-><c- p>,</c-> <c- n>y</c-><c- p>;</c->
<c- b>void</c-> <c- nf>relaxed</c-><c- p>()</c-> <c- p>{</c->
  <c- n>x</c-><c- p>.</c-><c- n>fetch_add</c-><c- p>(</c-><c- mi>2</c-><c- p>,</c-> <c- n>std</c-><c- o>::</c-><c- n>memory_order_relaxed</c-><c- p>);</c->
  <c- n>y</c-><c- p>.</c-><c- n>fetch_add</c-><c- p>(</c-><c- mi>2</c-><c- p>,</c-> <c- n>std</c-><c- o>::</c-><c- n>memory_order_relaxed</c-><c- p>);</c->
<c- p>}</c->
</pre>
   <p>We aren’t aware of compilers performing this optimization yet, but <a href="https://llvm.org/bugs/show_bug.cgi?id=16477">it is being
discussed</a>. <code class="highlight"><c- n>std</c-><c- o>::</c-><c- n>atomic_signal_fence</c-></code> could be used to prevent
this reordering and fusion, or one could use a stronger memory ordering for the
operations: this optimization is only valid on relaxed operations which aren’t
ordered with respect to each other.</p>
   <p>A compiler can tag all functions on whether they have atomic instructions or
not, and optimize around call sites accordingly. This could even be done for all
virtual overrides when we can enumerate them, and can be used to carve out
different <a href="http://www.hpl.hp.com/techreports/2011/HPL-2011-57.pdf">inteference-free
regions</a>.</p>
   <p>Fence instructions are generated as a consequence of C++'s <code class="highlight"><c- n>std</c-><c- o>::</c-><c- n>atomic_thread_fence</c-></code> as well as, on some architectures, atomic
operations. Fence instructions tend to be expensive, and removing redundant ones
as well as positioning them optimally leads to great performance gains, while
keeping the code correct and simple. This is <a href="https://reviews.llvm.org/D5758">currently under review in LLVM</a>.</p>
   <p>Not all compiler optimizations are valid on atomics, this topic is still under <a href="http://www.di.ens.fr/~zappa/readings/c11comp.pdf">active research</a>.</p>
   <h3 class="heading settled" data-level="1.2" id="opt-around"><span class="secno">1.2. </span><span class="content">Optimizations Around Atomics</span><a class="self-link" href="#opt-around"></a></h3>
   <p>Compilers can optimize non-atomic memory accesses before and after atomic
accesses. A somewhat surprising example is that the following code can be (<a href="https://reviews.llvm.org/D4845">and is</a>!) transformed as shown, where <code class="highlight"><c- n>x</c-></code> is a non-atomic global.</p>
<pre class="highlight"><c- b>int</c-> <c- n>x</c-> <c- o>=</c-> <c- mi>0</c-><c- p>;</c->
<c- n>std</c-><c- o>::</c-><c- n>atomic</c-><c- o>&lt;</c-><c- b>int</c-><c- o>></c-> <c- n>y</c-><c- p>;</c->
<c- b>int</c-> <c- nf>dso</c-><c- p>()</c-> <c- p>{</c->
  <c- n>x</c-> <c- o>=</c-> <c- mi>0</c-><c- p>;</c->
  <c- b>int</c-> <c- n>z</c-> <c- o>=</c-> <c- n>y</c-><c- p>.</c-><c- n>load</c-><c- p>(</c-><c- n>std</c-><c- o>::</c-><c- n>memory_order_seq_cst</c-><c- p>);</c->
  <c- n>y</c-><c- p>.</c-><c- n>store</c-><c- p>(</c-><c- mi>0</c-><c- p>,</c-> <c- n>std</c-><c- o>::</c-><c- n>memory_order_seq_cst</c-><c- p>);</c->
  <c- n>x</c-> <c- o>=</c-> <c- mi>1</c-><c- p>;</c->
  <c- k>return</c-> <c- n>z</c-><c- p>;</c->
<c- p>}</c->
</pre>
   <p>Becomes:</p>
<pre class="highlight"><c- b>int</c-> <c- n>x</c-> <c- o>=</c-> <c- mi>0</c-><c- p>;</c->
<c- n>std</c-><c- o>::</c-><c- n>atomic</c-><c- o>&lt;</c-><c- b>int</c-><c- o>></c-> <c- n>y</c-><c- p>;</c->
<c- b>int</c-> <c- nf>dso</c-><c- p>()</c-> <c- p>{</c->
  <c- c1>// Dead store eliminated.</c->
  <c- b>int</c-> <c- n>z</c-> <c- o>=</c-> <c- n>y</c-><c- p>.</c-><c- n>load</c-><c- p>(</c-><c- n>std</c-><c- o>::</c-><c- n>memory_order_seq_cst</c-><c- p>);</c->
  <c- n>y</c-><c- p>.</c-><c- n>store</c-><c- p>(</c-><c- mi>0</c-><c- p>,</c-> <c- n>std</c-><c- o>::</c-><c- n>memory_order_seq_cst</c-><c- p>);</c->
  <c- n>x</c-> <c- o>=</c-> <c- mi>1</c-><c- p>;</c->
  <c- k>return</c-> <c- n>z</c-><c- p>;</c->
<c- p>}</c->
</pre>
   <p>The intuition behind the dead store elimination optimization is that the only
way another thread could have observed the dead store elimination is if their
code had been racy in the first place: only a <code class="highlight"><c- n>release</c-></code>/<code class="highlight"><c- n>acquire</c-></code> pair could have been synchronized with
another thread that observed the store (see <a href="http://www.di.ens.fr/~zappa/readings/pldi13.pdf">this paper</a> for
details). Sequentially consistent accesses are <code class="highlight"><c- n>acquire</c-></code>/<code class="highlight"><c- n>release</c-></code>, the key in this example is having the <code class="highlight"><c- n>release</c-></code> store come before the <code class="highlight"><c- n>acquire</c-></code> load and
synchronize with another thread (which the loop does by observing changes in <code class="highlight"><c- n>y</c-></code>).</p>
   <p>The following code, with a different store/load ordering and using <code class="highlight"><c- n>release</c-></code>/<code class="highlight"><c- n>acquire</c-></code> memory ordering, can also be
transformed as shown (but currently isn’t, at least in LLVM).</p>
<pre class="highlight"><c- b>int</c-> <c- n>x</c-> <c- o>=</c-> <c- mi>0</c-><c- p>;</c->
<c- n>std</c-><c- o>::</c-><c- n>atomic</c-><c- o>&lt;</c-><c- b>int</c-><c- o>></c-> <c- n>y</c-><c- p>;</c->
<c- b>int</c-> <c- nf>rlo</c-><c- p>()</c-> <c- p>{</c->
  <c- n>x</c-> <c- o>=</c-> <c- mi>0</c-><c- p>;</c->
  <c- n>y</c-><c- p>.</c-><c- n>store</c-><c- p>(</c-><c- mi>0</c-><c- p>,</c-> <c- n>std</c-><c- o>::</c-><c- n>memory_order_release</c-><c- p>);</c->
  <c- b>int</c-> <c- n>z</c-> <c- o>=</c-> <c- n>y</c-><c- p>.</c-><c- n>load</c-><c- p>(</c-><c- n>std</c-><c- o>::</c-><c- n>memory_order_acquire</c-><c- p>);</c->
  <c- n>x</c-> <c- o>=</c-> <c- mi>1</c-><c- p>;</c->
  <c- k>return</c-> <c- n>z</c-><c- p>;</c->
<c- p>}</c->
</pre>
   <p>Becomes:</p>
<pre class="highlight"><c- b>int</c-> <c- n>x</c-> <c- o>=</c-> <c- mi>0</c-><c- p>;</c->
<c- n>std</c-><c- o>::</c-><c- n>atomic</c-><c- o>&lt;</c-><c- b>int</c-><c- o>></c-> <c- n>y</c-><c- p>;</c->
<c- b>int</c-> <c- nf>rlo</c-><c- p>()</c-> <c- p>{</c->
  <c- c1>// Dead store eliminated.</c->
  <c- n>y</c-><c- p>.</c-><c- n>store</c-><c- p>(</c-><c- mi>0</c-><c- p>,</c-> <c- n>std</c-><c- o>::</c-><c- n>memory_order_release</c-><c- p>);</c->
  <c- c1>// Redundant load eliminated.</c->
  <c- n>x</c-> <c- o>=</c-> <c- mi>1</c-><c- p>;</c->
  <c- k>return</c-> <c- mi>0</c-><c- p>;</c-> <c- c1>// Stored value propagated here.</c->
<c- p>}</c->
</pre>
   <p>The above example’s load can be eliminated because there was no synchronization
with another thread: even if the <code class="highlight"><c- n>release</c-></code> is followed by an <code class="highlight"><c- n>acquire</c-></code> the compiler is allowed to assume that the stored value
wasn’t modified before the subsequent load, and that the load is therefore
redundant.</p>
   <p>Whereas the following code must (and does!) remain the same:</p>
<pre class="highlight"><c- b>int</c-> <c- n>x</c-> <c- o>=</c-> <c- mi>0</c-><c- p>;</c->
<c- n>std</c-><c- o>::</c-><c- n>atomic</c-><c- o>&lt;</c-><c- b>int</c-><c- o>></c-> <c- n>y</c-><c- p>;</c->
<c- b>int</c-> <c- nf>no</c-><c- p>()</c-> <c- p>{</c->
  <c- n>x</c-> <c- o>=</c-> <c- mi>0</c-><c- p>;</c->
  <c- n>y</c-><c- p>.</c-><c- n>store</c-><c- p>(</c-><c- mi>0</c-><c- p>,</c-> <c- n>std</c-><c- o>::</c-><c- n>memory_order_release</c-><c- p>);</c->
  <c- k>while</c-> <c- p>(</c-><c- o>!</c-><c- n>y</c-><c- p>.</c-><c- n>load</c-><c- p>(</c-><c- n>std</c-><c- o>::</c-><c- n>memory_order_acquire</c-><c- p>));</c->
  <c- n>x</c-> <c- o>=</c-> <c- mi>1</c-><c- p>;</c->
  <c- k>return</c-> <c- n>z</c-><c- p>;</c->
<c- p>}</c->
</pre>
   <p>Other optimizations such as global value ordering across atomics can be applied.</p>
   <h3 class="heading settled" data-level="1.3" id="mutex"><span class="secno">1.3. </span><span class="content">Mutex: Safer than Atomics?</span><a class="self-link" href="#mutex"></a></h3>
   <p>The same optimization potential applies to C++'s <code class="highlight"><c- n>std</c-><c- o>::</c-><c- n>mutex</c-></code>:
locking a mutex is equivalent to <code class="highlight"><c- n>acquire</c-></code> memory ordering, and
unlocking a mutex is equivalent to <code class="highlight"><c- n>release</c-></code> memory ordering. Using a
mutex correctly is slightly easier because the API is simpler than atomic’s API.</p>
   <p>Some current implementations rely on pthread’s mutex, which may not expose all
optimization opportunities because the compiler may not know how to handle the
slow-path futex (usually a syscall), or because the implementation is in a
different translation unit. The optimization difficulties can be overcome by
teaching the compiler to treat <code class="highlight"><c- n>std</c-><c- o>::</c-><c- n>mutex</c-></code> or pthread specially, or
by <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4195.pdf">making
it practical to implement mutexes in pure C++</a>. Optimization across
translation units, such as through link-time optimizations, or optimizations
relying on escape analysis, can also help expose more opportunities.</p>
   <h3 class="heading settled" data-level="1.4" id="opt-without"><span class="secno">1.4. </span><span class="content">Optimizations without Atomics</span><a class="self-link" href="#opt-without"></a></h3>
   <p>Another interesting optimization is to use potentially shared memory locations
(on the stack, heap and globals) as scratch storage, if the compiler can prove
that they are not accessed in other threads concurrently. This is spelled out in
the C++11 standard in section 1.10 ¶22. For example the following transformation
could occur:</p>
<pre class="highlight"><c- c1>// Some code, but no synchronization.</c->
<c- o>*</c-><c- n>p</c-> <c- o>=</c-> <c- mi>1</c-><c- p>;</c-> <c- c1>// Can be on stack, heap or global.</c->
</pre>
   <p>Becomes:</p>
<pre class="highlight"><c- c1>// ...</c->
<c- o>*</c-><c- n>p</c-> <c- o>=</c-> <c- n>RAX</c-><c- p>;</c-> <c- c1>// Spill temporary value.</c->
<c- c1>// ...</c->
<c- n>RAX</c-> <c- o>=</c-> <c- o>*</c-><c- n>p</c-><c- p>;</c-> <c- c1>// Restore temporary value.</c->
<c- c1>// ...</c->
<c- o>*</c-><c- n>p</c-> <c- o>=</c-> <c- mi>1</c-><c- p>;</c->
</pre>
   <p>Since we write to <code class="highlight"><c- o>*</c-><c- n>p</c-></code> and there is no synchronization operations,
other threads do not read/write <code class="highlight"><c- o>*</c-><c- n>p</c-></code> without exercising undefined
behavior. We can therefore use it as scratch storage—and thus reduce stack frame
size—without changing the observable behavior of the program. This requires
escape analysis: the compiler must see the full scope of memory location <code class="highlight"><c- n>p</c-></code>, or must know that leaf functions don’t capture <code class="highlight"><c- n>p</c-></code> and aren’t used concurrently, for this optimization to be valid.</p>
   <h3 class="heading settled" data-level="1.5" id="arch"><span class="secno">1.5. </span><span class="content">Architecture and Implementation Specific Optimizations</span><a class="self-link" href="#arch"></a></h3>
   <p>Optimizations can sometimes be made per-architecture, or even per specific
implementation of an architecture. Compilers can usually be told to target
specific architectures, CPUs or attributes using flags such as <code class="highlight"><c- o>-</c-><c- n>march</c-></code>, <code class="highlight"><c- o>-</c-><c- n>mcpu</c-></code>, <code class="highlight"><c- o>-</c-><c- n>mattr</c-></code>.</p>
   <p>Spinloops are usually implemented with an <code class="highlight"><c- n>acquire</c-></code> load, which are
equivalent to a <code class="highlight"><c- n>relaxed</c-></code> load followed by an <code class="highlight"><c- n>acquire</c-></code> fence in the loop. On some architecture implementations it may make sense to
hoist the fence outside the loop, but how and when to do this is architecture
specific. In a similar way, mutexes usually want to be implemented as a spinloop
with exponential randomized backoff followed by a futex. The right
implementation of mutexes is highly platform-dependent.</p>
   <p>Instructions can also be implemented in manners that are nominally incorrect for
the architecture in general, but happen to be correct for specific
implementations of the architecture. For example, <code class="highlight"><c- n>release</c-></code> fences
should lower to <code class="highlight"><c- n>dmb</c-> <c- n>ish</c-></code> on ARM, but <a href="http://lists.llvm.org/pipermail/llvm-commits/Week-of-Mon-20130701/thread.html#179911">on
Apple’s Swift processor</a> they lower to <code class="highlight"><c- n>dmb</c-> <c- n>ishst</c-></code> instead, which
would be incorrect on other ARM processors. Some ARM processors can go even
further and remove all <code class="highlight"><c- n>dmb</c-></code> which aren’t system-wide because their
memory model is much stronger than ARM’s prescribed model.</p>
   <p>Some architectures support transactional memory. A compiler can use this
knowledge to make many consecutive atomic writes into a single atomic
transaction, and retry on commit failure. It can also speculate that many reads
and writes aren’t accessed concurrently, or that certain locks aren’t contended,
and fall back to a slow path, or to smaller transactions, if a commit failure
limit is reached. Such approaches have been implemented using Intel’s <a href="https://queue.acm.org/detail.cfm?id=2579227">RTM and HLE</a> extensions.</p>
   <p>Other architectures do dynamic binary translation behind the scenes, and also
use transactional memory. This can lead to further in-hardware optimizations as
well as fairly hard to predict behavior: sometimes races aren’t observed because
big transactions commit, and other times they do occur because transactions are
smaller. This certainly makes micro-benchmarking hard, if not impossible.</p>
   <p>The same applies for simulators and emulators which often just-in-time translate
the code they’re executing—leading to hard-to-predict behavior—and which also
often emulate multi-core systems using cooperative thread switching—leading to
predictable interleaving which is easier to optimize for the simulator.</p>
   <h3 class="heading settled" data-level="1.6" id="volatile"><span class="secno">1.6. </span><span class="content">Volatility</span><a class="self-link" href="#volatile"></a></h3>
   <p>Atomic operations are unsuitable to express that memory locations can be
externally modified. Indeed, <code class="highlight"><c- k>volatile</c-></code> (or <code class="highlight"><c- k>volatile</c-> <c- n>atomic</c-></code>) should be used in these circumstances.</p>
   <p>Shared memory isn’t explicitly defined by the C++ standard, yet programmers
often use operating system APIs to map the same physical memory location onto
multiple virtual addresses in the same process, or across processes. A
sufficiently advanced compiler, performing some of the optimizations described
above, can seriously harm code which uses shared memory naïvely.</p>
   <p>The C++ standard says that lock-free atomic operations must be <em>address
free</em> to address such issues, but this mandate isn’t normative.</p>
   <h2 class="heading settled" data-level="2" id="takeaways"><span class="secno">2. </span><span class="content">Takeaways</span><a class="self-link" href="#takeaways"></a></h2>
   <h3 class="heading settled" data-level="2.1" id="committee"><span class="secno">2.1. </span><span class="content">For the Standards Committee</span><a class="self-link" href="#committee"></a></h3>
   <p>Don’t assume that these optimizations don’t occur, but rather encourage
them. Standardize more common practice that enable to-the-metal
optimizations. Provide more libraries that make it easy to use concurrency and
parallelism and hard to get it wrong.</p>
   <h3 class="heading settled" data-level="2.2" id="devs"><span class="secno">2.2. </span><span class="content">For Developers</span><a class="self-link" href="#devs"></a></h3>
   <p>Drop assembly: it can’t be optimized as well and is only tuned to the
architectures that existed when you originally wrote the code. File bugs when
performance expectations aren’t met by the compiler. Suggest to the standard
committee new idiomatic patterns which enable concurrency and parallelism. Use
the tooling available to you, such as ThreadSanitizer, to find races in your
code.</p>
   <h3 class="heading settled" data-level="2.3" id="hw"><span class="secno">2.3. </span><span class="content">For Hardware vendors</span><a class="self-link" href="#hw"></a></h3>
   <p>Showcase your hardware’s strengths.</p>
   <h3 class="heading settled" data-level="2.4" id="compiler"><span class="secno">2.4. </span><span class="content">For Compiler Writers</span><a class="self-link" href="#compiler"></a></h3>
   <p>Get back to work, there’s so much more to optimize… and so much code to break!
Help users write good code: the compiler should provide diagnostics when it
detects anti-patterns or misuses of atomics.</p>
   <h2 class="heading settled" data-level="3" id="acknowledgement"><span class="secno">3. </span><span class="content">Acknowledgement</span><a class="self-link" href="#acknowledgement"></a></h2>
   <p>Thanks to Robin Morisset, Dmitry Vyukov, Chandler Carruth, Jeffrey Yasskin, Paul
McKenney, Lawrence Crowl, Hans Boehm and Torvald Riegel for their reviews,
corrections and ideas.</p>
  </main>
<script>
(function() {
  "use strict";
  var collapseSidebarText = '<span aria-hidden="true">←</span> '
                          + '<span>Collapse Sidebar</span>';
  var expandSidebarText   = '<span aria-hidden="true">→</span> '
                          + '<span>Pop Out Sidebar</span>';
  var tocJumpText         = '<span aria-hidden="true">↑</span> '
                          + '<span>Jump to Table of Contents</span>';

  var sidebarMedia = window.matchMedia('screen and (min-width: 78em)');
  var autoToggle   = function(e){ toggleSidebar(e.matches) };
  if(sidebarMedia.addListener) {
    sidebarMedia.addListener(autoToggle);
  }

  function toggleSidebar(on) {
    if (on == undefined) {
      on = !document.body.classList.contains('toc-sidebar');
    }

    /* Don't scroll to compensate for the ToC if we're above it already. */
    var headY = 0;
    var head = document.querySelector('.head');
    if (head) {
      // terrible approx of "top of ToC"
      headY += head.offsetTop + head.offsetHeight;
    }
    var skipScroll = window.scrollY < headY;

    var toggle = document.getElementById('toc-toggle');
    var tocNav = document.getElementById('toc');
    if (on) {
      var tocHeight = tocNav.offsetHeight;
      document.body.classList.add('toc-sidebar');
      document.body.classList.remove('toc-inline');
      toggle.innerHTML = collapseSidebarText;
      if (!skipScroll) {
        window.scrollBy(0, 0 - tocHeight);
      }
      tocNav.focus();
      sidebarMedia.addListener(autoToggle); // auto-collapse when out of room
    }
    else {
      document.body.classList.add('toc-inline');
      document.body.classList.remove('toc-sidebar');
      toggle.innerHTML = expandSidebarText;
      if (!skipScroll) {
        window.scrollBy(0, tocNav.offsetHeight);
      }
      if (toggle.matches(':hover')) {
        /* Unfocus button when not using keyboard navigation,
           because I don't know where else to send the focus. */
        toggle.blur();
      }
    }
  }

  function createSidebarToggle() {
    /* Create the sidebar toggle in JS; it shouldn't exist when JS is off. */
    var toggle = document.createElement('a');
      /* This should probably be a button, but appearance isn't standards-track.*/
    toggle.id = 'toc-toggle';
    toggle.class = 'toc-toggle';
    toggle.href = '#toc';
    toggle.innerHTML = collapseSidebarText;

    sidebarMedia.addListener(autoToggle);
    var toggler = function(e) {
      e.preventDefault();
      sidebarMedia.removeListener(autoToggle); // persist explicit off states
      toggleSidebar();
      return false;
    }
    toggle.addEventListener('click', toggler, false);


    /* Get <nav id=toc-nav>, or make it if we don't have one. */
    var tocNav = document.getElementById('toc-nav');
    if (!tocNav) {
      tocNav = document.createElement('p');
      tocNav.id = 'toc-nav';
      /* Prepend for better keyboard navigation */
      document.body.insertBefore(tocNav, document.body.firstChild);
    }
    /* While we're at it, make sure we have a Jump to Toc link. */
    var tocJump = document.getElementById('toc-jump');
    if (!tocJump) {
      tocJump = document.createElement('a');
      tocJump.id = 'toc-jump';
      tocJump.href = '#toc';
      tocJump.innerHTML = tocJumpText;
      tocNav.appendChild(tocJump);
    }

    tocNav.appendChild(toggle);
  }

  var toc = document.getElementById('toc');
  if (toc) {
    createSidebarToggle();
    toggleSidebar(sidebarMedia.matches);

    /* If the sidebar has been manually opened and is currently overlaying the text
       (window too small for the MQ to add the margin to body),
       then auto-close the sidebar once you click on something in there. */
    toc.addEventListener('click', function(e) {
      if(e.target.tagName.toLowerCase() == "a" && document.body.classList.contains('toc-sidebar') && !sidebarMedia.matches) {
        toggleSidebar(false);
      }
    }, false);
  }
  else {
    console.warn("Can't find Table of Contents. Please use <nav id='toc'> around the ToC.");
  }

  /* Wrap tables in case they overflow */
  var tables = document.querySelectorAll(':not(.overlarge) > table.data, :not(.overlarge) > table.index');
  var numTables = tables.length;
  for (var i = 0; i < numTables; i++) {
    var table = tables[i];
    var wrapper = document.createElement('div');
    wrapper.className = 'overlarge';
    table.parentNode.insertBefore(wrapper, table);
    wrapper.appendChild(table);
  }

})();
</script>